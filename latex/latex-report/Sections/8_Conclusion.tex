%================================================================
\section{Conclusion}\label{sec:Conclusion}
%================================================================

Inspired by \cite{Carleo_2017}, we have implemented a formalism using the unsupervised machine learning method \textit{restricted Boltzmann machine} (RBM) to study interacting many-particle systems. In particular, we have have used Gaussian-binary RBMs to model the wave function. In order to learn the parameters of the model, we have used a variational Monte Carlo (VMC) approach together with gradient descent optimization. For the VMC approach we consider the two Markov chain Monte Carlo (MCMC) sampling algorithms \textit{random walk Metropolis }, which is more of a brute-force sampling routine, and the \textit{Langevin Metropolis-Hastings}, which uses importance sampling. For gradient descent we have used the ADAM optimizer. We were able to accurately estimate the ground state energy for the simple system with a single one-dimensional particle, and found that, in this case, the RBM was more lenient when it came which settings produced accurate results. We found the best approximation to the ground state energy to be $E_0 = 0.499999 \pm 3\cdot10^{-6}$ a.u with ground truth $E_0=0.5$ a.u, using he RWM sampling algorithm. For the more complicated case with a couple of two-dimensional particles with repulsive interaction, finding optimal settings was more difficult. Here, we were able to obtain an energy estimate within one decimal point accuracy, $E_0 = 3.059 \pm 0.008$ a.u, of the ground truth, $E_0=3.0$ a.u, for specific settings, but others yielded estimates with significantly larger discrepancy. Our cost function is based solely on minimization of the expectation value of the energy, $\langle E \rangle$, and it might be beneficial to construct a cost function based on minimizing the variance, $\mathrm{Var}(E)$, or on minimizing both $\langle E \rangle$ and $\mathrm{Var}(E)$. 



% We consider two Markov chain Monte Carlo (MCMC) sampling algorithms; (i) the common random walk Metropolis (RWM) which explores the local neighborhood of the current state of the Markov chain using proposals from a symmetric probability distribution, and (ii) an algorithm based on the the nonlinear diffusion described by the Fokker-Planck and Langevin equations where the proposals are driven according to the gradient flow of the probability density of the trial wave function. The drift introduced in the second algorithm will typically move the Markov chain faster towards the center of the target distribution and thus mix faster than the plain RWM algorithm. We refer to the second algorithm as Langevin Metropolis-Hastings (LMH) due to its resemblance to Langevin Monte-Carlo type algorithms such as the Metropolis-adjusted Langevin algorithm (MALA) \citep{MALA}. 



% we have developed from scratch formalism and software for us- ing unsupervised machine learning methods to study interacting many-particle systems. 
%The MCMC sampling algorithms using the NQS trial wave function reached a high accuracy for the quantum dot in the single-dimensional harmonic oscillator trap, with a precision of order $10^{-6}$. The approximation to the ground state was found to be $E_0 = 0.499999 \pm 3\cdot\10^{-6}$ a.u. As for the system of two interacting electrons in the isotropic two-dimensional harmonic oscillator trap, the upper bound approximation to the ground state energy was $E_0 = 3.059\pm 0.008$ a.u. 

%Cost function - might be beneficial to use a cost function either based on minimizing the variance, Var(E), or on minimizing both $\langle E \rangle$ and Var(E). 

%The training itself is stochastic, and here we train the RBM parameters once, and then sample with the trained parameters with multiple Markov chains. A more rigorous approach would be to compare statistics across multiple training rounds with the same system and initial parameter settings

%Also train/optimize RBM scale

% The many-body wave function increases exponentially in complexity with the number of particles, and therefore, clever approximations to it is of great interest. The universal approximation theorem states that any function can be approximated to an arbitrary error by a neural network. We will therefore seek to implement an approach based on a machine learning approach. 
%An approach based on a neural network for solving the quantum mechanical wave function is still a relatively new, but an increasingly interesting prospect \citep{Saito_2018}. This paper analyzes two systems of electrons, a quantum dot in a one-dimensional harmonic oscillator trap and a pair of interacting electrons in an isotropic two-dimensional harmonic oscillator trap. We analyze the systems using an unsupervised learning method, the restricted Boltzmann machine (RBM), to simulate the wave function (known as a Neural-network Quantum State\citep{Carleo_2017}), and generate upper bound estimates to the ground state energies using two Monte Carlo approaches. We perform some coarse searches in the space of hyper parameters, like learning rate, batch-sizes for optimization and number of neurons in hidden layer. After finding the optimal set of parameters, we find that we approximate the ground state for the quantum dot in a single dimension to a high degree of precision. We find the best approximation to the ground state energy to be $E_0 = 0.499999 \pm 3\cdot10^{-6}$ a.u, using he RWM sampling algorithm. For the system of two interacting electrons in two-dimensional space we find the best approximation, again via the RWM sampling algorithm, to be $E_0 = 3.059 \pm 0.008$ a.u. Knowing the true ground state energy to be $E_0=3.0$ a.u \citep{PhysRevA.48.3561}, there is still plenty of room for improvement.
